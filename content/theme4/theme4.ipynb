{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1 align=\"center\"> THEME 4 - Donn√©es tabulaires </h1>\n",
    "\n",
    "### üéØ Objectifs\n",
    "\n",
    "- Manipuler des donn√©es tabulaires\n",
    "- Effectuer de l'analyse statistique\n",
    "\n",
    "### üìö Notions \n",
    "\n",
    "- [Exemple 1](#ex1):\n",
    "    - Cr√©er un Dataframe √† partir d'un dictionnaire\n",
    "    - Concat√©ner des donn√©es\n",
    "    - Indexer des donn√©es\n",
    "    - Filtrer les donn√©es par masque binaire\n",
    "    - Trier des colonnes num√©riques\n",
    "- [Exemple 2](#ex2):\n",
    "    - Ouvrir un fichier de donn√©es (CSV, etc...) et cr√©er un Dataframe\n",
    "    - Groupy et agr√©gation de donn√©es\n",
    "    - Renommer des colonnes\n",
    "    - Filtrer des colonnes textuelles par mots cl√©s\n",
    "- [Exemple 3](#ex3):\n",
    "    - Retirer et remplacer des valeurs nulles\n",
    "    - Detecter et retirer des lignes dupliqu√©es\n",
    "    - Cr√©er un index √† partir d'une colonne\n",
    "    - Effectuer des op√©rations matricielles\n",
    "    - Joindre deux Dataframes en fonction d'une cl√© commune\n",
    "    - Retirer des lignes et colonnes\n",
    "\n",
    "Un [lexique](#lexique) avec l'ensemble des fonctions qui ont √©t√© vues est disponible √† la fin du notebook.\n",
    "\n",
    "### üß∞ Librairies\n",
    "\n",
    "- **Pandas**: est une librairie libre-source Python largement utilis√©e dans la science des donn√©es, l'analyse des donn√©es et l'apprentissage machine. Il est construit au-dessus de la librairie Numpy ce qui lui offre une interface similaire et permet l'interop√©rabilit√© avec des fonctions numpy.\n",
    "\n",
    "### üîó R√©f√©rence\n",
    "\n",
    "- [R√©f√©rence API Pandas](https://pandas.pydata.org/docs/reference/index.html)\n",
    "\n",
    "### ‚öôÔ∏è Installation\n",
    "\n",
    "`pip install pandas`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"ex1\"><h2 align=\"center\"> Exemple 1 - Fleurs Iris </h2></a>\n",
    "\n",
    "### üìù Contexte\n",
    "\n",
    "L'Iris est un genre de plantes vivaces de la famille des Iridac√©es. Il existe une large vari√©t√© d'esp√®ces que l'on retrouve au Qu√©bec. L'Iris Versicolor est d'ailleurs l'un des embl√®mes officiels du Qu√©bec et se retrouve sur son drapeau.\n",
    "\n",
    "<center> <img width=400px src=\"assets/iris.jpg\" /> </center>\n",
    "\n",
    "\n",
    "La fleur peut √™tre violette, bleue ou pourpre et plus rarement blanche. Elle est constitu√©e de trois p√©tales minces et relev√©es dispos√©es √† l'int√©rieur de la fleur et de trois s√©pales plus longues et plus larges en forme de spatule et situ√©es √† l'ext√©rieur. \n",
    "\n",
    "### ‚≠ê Objectif\n",
    "\n",
    "- Cr√©er un jeu de donn√©es √† partir d'un dictionnaire Python contenant les donn√©es de fleurs d'iris.\n",
    "- Indexer et filtrer les donn√©es."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üíª Code\n",
    "\n",
    "Un `DataFrame` est une structure de donn√©es tabulaires qui permet de stocker et manipuler des donn√©es de fa√ßon intuitive. Les donn√©es tabulaires sont organis√©es sous plusieurs colonnes avec plusieurs entr√©es qui forment des lignes. Dans Pandas, une colonne de donn√©es est aussi appel√©e une `Series`.\n",
    "\n",
    "Il y a aussi la possibilit√© de cr√©er un index. Grossi√®rement, un index est une colonne sp√©ciale qui contient les identifiants des lignes. Par d√©faut, si on ne sp√©cifie pas un index lors de la cr√©ation d'un `DataFrame`, celui-ci est cr√©√© automatiquement et correspond au num√©ro de ligne. Ce num√©ro est associ√© directement √† une ligne, cela veut dire que si on trie une colonne du `DataFrame`, l'index sera aussi tri√©.\n",
    "\n",
    "La fa√ßon la plus simple de cr√©er un `DataFrame` est de partir d'un objet Python. La nature de cet objet change en fonction du format des donn√©es:\n",
    "\n",
    "- *Donn√©es colonnes*: L'objet est un dictionnaire o√π les cl√©s sont les noms des colonnes, et o√π les valeurs sont des listes de m√™me taille qui vont constituer les colonnes. C'est le format qui sera utilis√© dans cet exemple.\n",
    "- *Donn√©es lignes*: L'objet est une liste de dictionnaires, o√π chaque dictionnaire ont les m√™mes cl√©s et poss√®de une seule valeur par cl√©.\n",
    "\n",
    "Ces deux formats sont interchangeables en fonction de l'application et ont chacun des forces et faiblesses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint as pp  # Pretty Print un objet Python comme un dictionnaire\n",
    "\n",
    "# Cr√©ation d'un DataFrame (df) √† partir d'un dictionnaire Python\n",
    "# ---------------------------------------------------------------\n",
    "# Pour cr√©er un DataFrame √† partir d'un dictionnaire, les cl√©s doivent contenir des listes de donn√©es, si une seule\n",
    "# valeur est associ√©e √† une cl√©, la valeur est dupliqu√©e pour chaque ligne du DataFrame (ici c'est le cas pour Location)\n",
    "df_iris = pd.DataFrame(\n",
    "    {\n",
    "        \"Date\": pd.to_datetime(\"2022-06-15\"),  # Conversion d'un texte en date\n",
    "        \"Location\": \"Canada\",  # Colonne location avec une valeur qui sera rep√©t√©e\n",
    "        \"Esp√®ce\": [\"Versicolor\", \"Setosa\", \"Setosa\", \"Virginica\"],  # Liste python de mots\n",
    "        \"Petale_long\": [5.1, 1.5, 1.6, 5.5],  # Liste python de nombres\n",
    "        \"Petale_larg\": np.array([1.2, 0.2, 0.3, 2.1]),  # Numpy array\n",
    "    },\n",
    "    index=[\"fleur_0\", \"fleur_1\", \"fleur_2\", \"fleur_3\"],  # D√©finir l'index (facultatif)\n",
    ")\n",
    "\n",
    "# Afficher le df (fonctionne seulement sur un notebook jupyter)\n",
    "df_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois le `DataFrame` cr√©√©, il est possible d'obtenir des informations sur son contenu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_iris.shape)  # Forme du df (lignes, colonnes)\n",
    "print(df_iris.columns)  # Liste des colonnes du df\n",
    "print(df_iris.index)  # Liste des index du df\n",
    "print(df_iris.dtypes[\"Petale_long\"])  # Type de donn√©es d'une colonne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois un `DataFrame` cr√©√©, il est possible d'y ajouter des lignes ou colonnes avec la m√©thode `pd.concat()`. Cette m√©thode prend en param√®tre une liste de `DataFrame` √† concatener sur un axe. Dans le cas d'une simple concatenation d'une seule colonne, on peut passer en argument une `Series` √©galement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concater une nouvelle fleur dans le tableau\n",
    "# ---------------------------------------------------------------\n",
    "# Cr√©ation du df qui contient les infos de la nouvelle fleur\n",
    "df_iris_0 = pd.DataFrame(\n",
    "    {\n",
    "        \"Date\": pd.to_datetime(\"2020-01-23\"),\n",
    "        \"Location\": \"Malte\",\n",
    "        \"Esp√®ce\": \"Pseudacorus\",\n",
    "        \"Petale_long\": 5.4,\n",
    "        \"Petale_larg\": 2.2,\n",
    "    },\n",
    "    index=[\"fleur_4\"],\n",
    ")\n",
    "\n",
    "df_iris = pd.concat([df_iris, df_iris_0], axis=0)  # Concat√©nation sur les lignes\n",
    "\n",
    "df_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter une nouvelle colonne pour la couleur\n",
    "# ---------------------------------------------------------------\n",
    "# Cr√©er une Serie avec la liste des couleurs (m√™me taile que le nb de lignes de df_iris)\n",
    "series_color = pd.Series(\n",
    "    [\"Violet\", \"Violet\", \"Violet\", \"Violet\", \"Jaune\"],  # Donn√©es de la colonne\n",
    "    name=\"Couleur\",  # Nom de la colonne/S√©rie\n",
    "    index=df_iris.index,  # D√©finir l'index, ici n√©c√©ssaire pour la concat√©nation\n",
    ")\n",
    "\n",
    "df_iris = pd.concat([df_iris, series_color], axis=1)  # Concat√©nation sur les colonnes\n",
    "\n",
    "df_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'indexation des donn√©es dans pandas est assez d√©licate puisqu'il existe 3 formes d'indexation.\n",
    "\n",
    "- Indexation directe des colonnes: `df[<nom_col>]` ou `df[[<nom_col1>, <nom_col2>, ...]]`. Permet de selectionner l'enti√®ret√© d'une ou plusieurs colonnes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris[\"Esp√®ce\"]  # Selectionner une colonne (retourne une S√©rie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Avec `df.loc[<index ou liste>, <nom_colonne ou liste>]`. Utile pour indexer une ou plusieurs colonnes avec un index particulier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris.loc[\"fleur_0\", \"Esp√®ce\"]  # Esp√®ce de la fleur_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris.loc[:, [\"Petale_long\", \"Petale_larg\"]]  # Toutes les lignes des colonnes \"Petale_long\" et \"Petale_larg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Avec `df.iloc[<no_ligne>, <no_colonne>]`. Similaire √† `.loc` mais utilise **uniquement** des indices num√©riques. Cette m√©thode est similaire √† l'indexation d'une matrice dans Numpy (vu dans le Th√®me 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris.iloc[0, -1]  # Selectionner la premi√®re ligne de la derni√®re colonne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris.iloc[:3, -2:]  # Selectionner les 3 premi√®res lignes des 2 derni√®res colonnes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise un `DataFrame` g√©n√©ralement lorsque l'on veut analyser un sous-ensemble de donn√©es avec une caract√©ristique particuli√®re. Cette caract√©ristique peut √™tre isol√©e en filtrant les donn√©es. L'une des m√©thodes est l'utilisation de masques binaires, similaires √† ceux employ√©s avec les Numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtre = df_iris[\"Esp√®ce\"] == \"Setosa\"  # Masque binaire issu de l'√©valuation de la condition \"Esp√®ce\" == \"Setosa\"\n",
    "filtre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris.index[filtre]  # Voir les index des lignes qui respectent le masque binaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris.loc[filtre, :]  # Appliquer le masque au df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prendre les iris avec une largeur de petale sup√©rieure √† 1 ET une longueur de petale inf√©rieure √† 5.2, et selectionner\n",
    "# uniquement les colonnes \"Esp√®ce\", \"Petale_long\" et \"Petale_larg\"\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "# Rappel: ET = &, OU = |\n",
    "# Attention: ne pas oublier les parenth√®ses entre chaque masque binaire\n",
    "filtre2 = (df_iris[\"Petale_larg\"] > 1) & (df_iris[\"Petale_long\"] < 5.2)\n",
    "df_iris.loc[filtre2, [\"Esp√®ce\", \"Petale_long\", \"Petale_larg\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plut√¥t que d'encha√Æner plusieurs masques binaires pour √©valuer plusieurs √©galit√©s, on peut utiliser `.isin` pour isoler les lignes d'une colonne qui contiennent l'une des valeurs possibles d'une liste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris.loc[\n",
    "    df_iris[\"Esp√®ce\"].isin([\"Setosa\", \"Virginica\"]), :\n",
    "]  # Selectionner les iris de type \"Setosa\" ou \"Versicolor\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut aussi trier les donn√©es avec une ou plusieurs colonnes gr√¢ce √† `sort_values`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trier le tableau par les valeurs de la colonne \"Petale_long\" en ordre d√©croissant\n",
    "df_iris.sort_values(by=\"Petale_long\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trier le tableau par les valeurs des colonnes \"Petale_long\" et \"Petale_larg\" en ordre croissant\n",
    "df_iris.sort_values(by=[\"Petale_long\", \"Petale_larg\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour calculer la surface rectangulaire occup√©e par une p√©tale, on peut utiliser une fonction Lambda. Cette fonction permet d'√©valuer une expression math√©matique sur chaque ligne du DataFrame. Avec la fonction `df.assign(<nom_col> = lambda x: <expression x>)` on ajoute une colonne qui contient la valeur calcul√©e pour la ligne `x` par la fonction Lambda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris = df_iris.assign(Aire=lambda x: x[\"Petale_long\"] * x[\"Petale_larg\"])\n",
    "df_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois que les op√©rations sont compl√©t√©s sur le `DataFrame`, il est simple de le convertir en dictionnaire avec la m√©thode `to_dict()` pour l'exporter par exemple. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selectionner les fleurs de type \"Setosa\" et \"Versicolor\" et les trier par ordre croissant de largeur de p√©tale\n",
    "new_df = df_iris.loc[df_iris[\"Esp√®ce\"].isin([\"Setosa\", \"Versicolor\"]), :].sort_values(by=\"Petale_larg\")\n",
    "\n",
    "df_dict = new_df.to_dict(\"list\")  # \"List\" pour format colonne et \"records\" pour format ligne\n",
    "\n",
    "pp.pprint(df_dict)  # Afficher le dictionnaire r√©sultant (eq. √† print(df_dict) mais plus lisible)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour des op√©rations matricielles, on peut aussi utiliser la m√©thode `to_numpy()` pour convertir des colonnes du DataFrame en matrice Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_petales = df_iris.loc[:, [\"Petale_long\", \"Petale_larg\"]].to_numpy()\n",
    "print(mat_petales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"ex2\"><h2 align=\"center\"> Exemple 2 - Transest√©rification du canola en biodiesel </h2></a>\n",
    "\n",
    "### üìù Contexte\n",
    "La transest√©rification est une r√©action catalytique permettant la production de biodiesel (sous forme d'esters m√©thyliques) √† partir d'huile v√©g√©tale et de m√©thanol. Dans cet exemple, l'huile v√©g√©tale utilis√©e est le canola et la r√©action est la suivante:\n",
    "\n",
    "<center>\n",
    "<img width=500px src=\"assets/reaction_biodiesel.png\" />\n",
    "</center>\n",
    "\n",
    "Les triglyc√©rides du canola r√©agissent avec l'alcool et produisent du biodiesel et du glyc√©rol. Une chromatographie est effectu√©e √† la suite de la r√©action pour analyser son contenu chimique.\n",
    "\n",
    "<center>\n",
    "<img width=500px src=\"assets/chromato_biodiesel.png\" />\n",
    "</center>\n",
    "\n",
    "Enfin, une analyse num√©rique dans le logiciel de chromatographie permet d'extraire les donn√©es des pics les plus importants. \n",
    "\n",
    "### ‚≠ê Objectif\n",
    "\n",
    "Faire la synth√®se des donn√©es exp√©rimentales gr√¢ce √† une agr√©gation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üíª Code\n",
    "\n",
    "Les donn√©es que l'on analyse sont habituellement stock√©es sur un disque dans un fichier. Il existe une multitude de formats qui existent et les plus utilis√©s sont: `CSV`, `JSON`, `IPC`, `HDF5` et `Parquet`. \n",
    "\n",
    "Dans Pandas, il y a [plusieurs](https://pandas.pydata.org/docs/reference/io.html) fonctions qui permettent d'ouvrir ces fichiers et de les convertir facilement en `DataFrame`. \n",
    "\n",
    "Pour ouvrir un fichier, la m√©thode est de la forme `pd.read_<format>(<fichier>)` et pour enregistrer un `DataFrame` dans un fichier, la m√©thode est de la forme `df.to_<format>(<fichier>)`.\n",
    "\n",
    "Pour cet exemple, on utilise le format de base: `CSV`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lecture du fichier CSV avec un s√©parateur \";\"\n",
    "df_bio = pd.read_csv(\"data/biodiesel.csv\", sep=\";\")\n",
    "\n",
    "df_bio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la science des donn√©es, l'un des outils fondamentaux est l'agr√©gation de donn√©es qui permet de regrouper les donn√©es appartenant √† un m√™me sous-groupe et en tirer plus facilement des r√©sultats num√©riques. \n",
    "\n",
    "Avec pandas, cela se fait avec la m√©thode `groupby` pour regrouper les donn√©es sur une ou plusieurs colonnes et `agg` pour sp√©cifier la m√©thode d'agr√©gation employ√©e, tr√®s souvent sur les donn√©es num√©riques. Apr√®s l'agr√©gation, une bonne pratique est de renommer les colonnes pour mieux repr√©senter les nouvelles colonnes, avec pandas on peut faire cela avec la m√©thode `rename`.\n",
    "\n",
    "Les op√©rations d'agr√©gation possibles sont:\n",
    "\n",
    "<a name=\"operations\"></a>\n",
    "| Op√©ration        | Description              |\n",
    "| ---------------- | ------------------------ |\n",
    "| `mean`, `median` | Moyenne, M√©diane         |\n",
    "| `count`          | Nombre d'√©l√©ments        |\n",
    "| `first`, `last`  | Premier, Dernier √©l√©ment |\n",
    "| `std`, `var`     | Ecart-type, Variance     |\n",
    "| `min`, `max`     | Minimum, Maximum         |\n",
    "| `sum`, `prod`    | Somme, Produit           |\n",
    "\n",
    "Ces op√©rations peuvent √™tre aussi directement utilis√©es sur un df (ou sur certaines lignes/colonnes) comme par exemple `df.mean(axis=1)` pour calculer la moyenne de chaque ligne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les colonnes sont renomm√©es en utilisant un dictionnaire o√π les cl√©s sont les anciens noms et les valeurs sont\n",
    "# les nouveaux noms\n",
    "new_col = {\"Time\": \"Avg Time\", \"Area\": \"Total Area\"}\n",
    "\n",
    "# Manipulation du df\n",
    "# -------------------------------------------------\n",
    "# Les √©tapes peuvent √™tre √©galement √©crites sur une seule ligne\n",
    "df_grouped_bio = (\n",
    "    df_bio.groupby(\"Name\", as_index=True)  # Regrouper les lignes par \"Name\", avec le nom comme index (facultatif)\n",
    "    .agg({\"Time\": \"mean\", \"Area\": \"sum\"})  # Sp√©cifier l'op√©ration d'aggregation sur les colonnes non-regroup√©es\n",
    "    .rename(columns=new_col)  # Renommer les colonnes\n",
    ")\n",
    "\n",
    "df_grouped_bio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour pouvoir filtrer les lignes qui correspondent √† une mol√©cule de biodiesel, on peut utiliser `df[<nom_col>].str.contains(<crit√®re>)` sur une colonne ou `df.index.str.contains(<crit√®re>)` sur un index de texte pour isoler les lignes qui contiennent une sous-chaine de charact√®res. Dans notre cas, on remarque que les mol√©cules de biodiesel contiennent un \"C\", ce sera donc le crit√®re choisi.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selectionner les index qui contiennent la lettre \"C\"\n",
    "df_grouped_bio.loc[df_grouped_bio.index.str.contains(\"C\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_bio_noidx = df_grouped_bio.reset_index()  # Cr√©er une copie du df avec l'index remis comme par d√©faut\n",
    "\n",
    "df_grouped_bio_noidx.loc[df_grouped_bio_noidx[\"Name\"].str.contains(\"C\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Astuces\n",
    "\n",
    "Le format CSV existe depuis tr√®s longtemps et sa simplicit√© lui permet d'√™tre tr√®s souvent disponible comme format d'exportation de donn√©es dans plusieurs logiciels. Cependant, il est loin d'√™tre tr√®s efficace et pr√©sente beaucoup de d√©savantages: lecture lente d'une colonne sp√©cifique, pas de compression par d√©faut, faible support pour les caract√®res sp√©ciaux et l'h√©t√©rog√©n√©it√© des types de donn√©es. Pour une faible quantit√© de donn√©es, le format CSV reste tr√®s pratique, toutefois, si l'on manipule une grande quantit√© de donn√©es, il est recommand√© d'utiliser le format [Parquet](https://en.wikipedia.org/wiki/Apache_Parquet). C'est un format moderne et tr√®s performant qui permet de stocker des donn√©es en prenant 2 √† 10 fois moins de place et avec une vitesse de lecture 10 √† 100 fois plus rapide. Parquet est int√©gr√© √† Pandas et peut √™tre utilis√© avec les m√©thodes `pd.read_parquet()` et `df.to_parquet()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"ex3\"><h2 align=\"center\"> Exemple 3 - √âmissions √©coinvent </h2></a>\n",
    "\n",
    "\n",
    "### üìù Contexte\n",
    "\n",
    "Ecoinvent est une association √† but non lucratif qui met √† disposition des donn√©es de haute qualit√© reli√©es aux √©missions de divers proc√©d√©s industriels. √Ä partir de leur base de donn√©es, des donn√©es ont √©t√© extraites dans un fichier csv avec:\n",
    "\n",
    "- Le ID du proc√©d√©\n",
    "- Le nom de la particule √©mise\n",
    "- Le num√©ro CAS de cette particule\n",
    "- L'unit√© utilis√©e pour mesurer l'√©mission\n",
    "- Le milieu d'√©mission\n",
    "- Le sous-milieu d'√©mission \n",
    "\n",
    "√Ä partir d'une liste des num√©ros CAS uniques, les ratios massique pour chaque mol√©cule ont √©t√© extraites dans un autre fichier csv. Cette extraction a √©t√© possible gr√¢ce aux librairies python open source: \n",
    "\n",
    "- [cirpy](https://github.com/mcs07/CIRpy) pour convertir le num√©ro CAS en repr√©sentation chimique.\n",
    "- [chempy](https://github.com/bjodah/chempy) pour obtenir les compositions chimiques. \n",
    "\n",
    "Ce fichier contient donc une colonne avec le num√©ro CAS et 118 colonnes pour chaque √©l√©ment atomique et son ratio massique dans la mol√©cule.\n",
    "\n",
    "### ‚≠ê Objectif\n",
    "\n",
    "- Ouvrir ces fichiers xlsx comme `DataFrame`.\n",
    "- Rejoindre les deux tableaux gr√¢ce au num√©ro CAS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üíª Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partie 1\n",
    "\n",
    "On commence par ouvrir les fichiers csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ecoinvent = pd.read_csv(\"data/ecoinvent.csv\", sep=\";\")\n",
    "df_chempy = pd.read_csv(\"data/chempy.csv\", sep=\";\")\n",
    "\n",
    "df_ecoinvent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.precision\", 2)  # Pour une meilleure clart√©e on affiche le df avec 2 chiffres apr√®s la virgule\n",
    "\n",
    "df_chempy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que le DataFrame `chempy` contient beaucoup de valeurs `NaN` qui correspondent √† des valeurs nulles. Pour √©viter d'avoir des erreurs lors d'un calcul de somme par exemple, il est pr√©f√©rable de remplacer les valeurs `NaN` par z√©ro.\n",
    "\n",
    "Pour une manipulation plus optimale, la plupart des op√©rations sont effectu√©es `inplace=True` pour modifier le DataFrame directement sans cr√©er des copies inutiles. Cela est √©quivalent √† faire `df = df.<methode>`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplacer toutes les valeurs nulles par 0\n",
    "df_chempy.fillna(0, inplace=True)\n",
    "\n",
    "df_chempy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "G√©n√©ralement, lors de la manipulation de donn√©es tabulaires, il est souvent tr√®s possible d'√™tre en pr√©sence de lignes dupliqu√©es. On peut v√©rifier √ßa avec la m√©thode `.duplicated()` qui renvoie un masque binaire avec `True` pour les lignes dupliqu√©es en trop. Dans notre cas, cette m√©thode est √©valu√©e uniquement sur les lignes de la colonne \"cas\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtre3 = df_chempy[\"cas\"].duplicated()  # Trouver les lignes avec un CAS dupliqu√©\n",
    "df_chempy.loc[filtre3, :].sort_values(by=\"cas\")  # Appliquer le filtre et trier par ordre croissant du CAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit donc qu'il y a 16 dupliqu√©es en trop dans le tableau. On peut les retirer du DataFrame avec la m√©thode `drop_duplicates()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chempy.drop_duplicates([\"cas\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partie 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour calculer la quantit√© molaire par gramme de substance, on doit multiplier les fractions massiques de chaque √©l√©ment par l'inverse de leur masse molaire respective, puis additionner les r√©sultats. Les masses molaires des √©l√©ments atomiques se trouvent dans un autre fichier csv: `table_periodique.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tbl_period = pd.read_csv(\"data/table_periodique.csv\", sep=\";\")\n",
    "\n",
    "df_tbl_period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'op√©ration que l'on veut faire est principalement une multiplication matricielle entre 2 matrices: A x B, sauf qu'ici on a des `DataFrame` plut√¥t que des matrices. La particularit√© qui explique que l'utilisation d'un `DataFrame` est plus judicieuse, est que la multiplication matricielle est effectu√©e uniquement entre les m√™mes √©l√©ments atomiques. Pandas s'occupe de l'alignement entre les colonnes du df A et les index du df B. Cependant, avant d'effectuer la multiplication, il faut s'assurer que les deux df sont de dimensions compatibles c'est √† dire que le nombre de colonnes de A est √©gal au nombre de lignes de B.\n",
    "\n",
    "On peut commencer par conditionner notre df B qui va contenir les masses molaires des √©l√©ments atomiques. On veut obtenir un df avec une seule colonne qui contient les masses molaires et les symboles des √©l√©ments comme index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dans le df_tbl_period, isoler les lignes des √©l√©ments qui sont pr√©sents dans le df_chempy\n",
    "df_tbl_period = df_tbl_period.loc[df_tbl_period[\"Symbol\"].isin(df_chempy.columns[df_chempy.columns != \"cas\"]), :]\n",
    "\n",
    "# Utiliser la colonne \"Symbol\" comme index\n",
    "df_tbl_period.set_index(\"Symbol\", inplace=True)\n",
    "\n",
    "# Selectionner uniquement la colonne des masses atomiques et l'inverser pour compl√©ter la cr√©ation du df B\n",
    "df_B = 1 / df_tbl_period[\"AtomicMass\"]\n",
    "\n",
    "df_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le df A n'est tout simplement que les colonnes des fractions massiques du `df_chempy`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A = df_chempy.loc[:, df_chempy.columns != \"cas\"]\n",
    "\n",
    "df_A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans Pandas, les op√©rations matricielles utilisent les m√™mes symboles qu'avec Numpy, cela veut dire que pour la multiplication matricielle on utilise `@`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er une nouvelle serie appel√©e qte avec le r√©sultat de la multiplication\n",
    "series_mass = pd.Series(df_A @ df_B, name=\"mass\")\n",
    "\n",
    "series_mass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, on peut concat√©ner notre nouvelle serie √† `df_chempy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatener le long des colonnes (axis=1)\n",
    "df_chempy = pd.concat([df_chempy, series_mass], axis=1)\n",
    "\n",
    "# On peut renommer une colonne avec la m√©thode df.rename\n",
    "# -------------------------------------------------\n",
    "#  On passe un dictionnaire avec comme cl√©s les anciens noms et comme valeurs les nouveaux noms de colonnes\n",
    "df_chempy.rename(columns={\"mass\": \"mol/g\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partie 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rejoindre plusieurs tableaux de donn√©es est une autre op√©ration fondamentale dans la science des donn√©es. Pour des donn√©es de type relationnelles, comme celles que l'on a, des tableaux peuvent √™tre joints √† partir d'une ou plusieurs cl√©s communes entre les deux tables. Dans notre cas, la cl√© commune est le num√©ro CAS. \n",
    "\n",
    "Dans pandas, cette op√©ration se fait avec la m√©thode `.merge()`. Il existe plusieurs types de merge que l'on peut faire: `inner`, `outer`, `left` et `right`, une explication compl√®te avec des exemples est disponible [ici](https://learnsql.com/blog/sql-joins-types-explained/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faire un merge de type \"left\" entre la df_ecoinvent (gauche) et la df_chempy (droite).\n",
    "# -------------------------------------------------\n",
    "# Explication: Cela veut dire que toutes les colonnes de df_chempy, sauf celle qui a servi de cl√© pour le merge, soit\n",
    "#              la colonne \"cas\", sont annex√©es √† la df_ecoinvent pour former le nouveau df: df_merged\n",
    "# Type \"left\": Chaque ligne du df_ecoinvent est associ√©e √† la ligne du df_chempy qui a le m√™me CAS et dans le cas ou le\n",
    "#              CAS n'existe pas dans df_chempy, la ligne devient vide.\n",
    "df_joined = pd.merge(\n",
    "    df_ecoinvent,\n",
    "    df_chempy,\n",
    "    left_on=\"cas\",\n",
    "    right_on=\"cas\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "df_joined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour retirer des lignes ou colonnes non d√©sir√©es ou vides, Pandas met √† disposition les m√©thodes `df.drop()` et `df.dropna()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retirer les lignes avec un CAS sp√©cifique\n",
    "df_joined.drop(index=df_joined.index[df_joined[\"cas\"] == \"001912-24-9\"], inplace=True)\n",
    "\n",
    "# Retirer une colonne\n",
    "df_joined.drop(columns=[\"unit\"], inplace=True)\n",
    "\n",
    "# Retirer les lignes avec au moins une valeur nulle\n",
    "df_joined.dropna(\n",
    "    axis=0,  # lignes = 0, colonnes = 1\n",
    "    how=\"any\",  # 'any' ou 'all'\n",
    "    thresh=None,  # Si 'any', nombre de valeurs n√©cessaires pour que la ligne soit supprim√©e\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Astuces\n",
    "\n",
    "- Lors de la manpulation des `DataFrame`, par souci de performance, il est important de comprendre l'ordre des op√©rations qui sont effectu√©es. G√©n√©ralement, il faut commencer par tout filtrage des donn√©es et retirer les lignes ou colonnes que l'on veut exclure avant de faire une op√©ration math√©matique.\n",
    "- Dans la plupart des cas, les donn√©es utilis√©es d√©passent rarement le million de lignes. Cependant, dans le cas contraire, il faut commencer √† prendre en compte la taille des donn√©es et ce que √ßa implique en terme d'utilisation de la m√©moire. Tr√®s souvent cela consiste √† limiter le nombre de copies que l'on fait et √† adopter une structure de tableau plus compacte afin de diminuer sa taille. C'est un sujet un peu plus avanc√© mais tout de m√™me interessant √† savoir si on a l'intention de travailler avec du Big Data et construire des algorithmes qui roulent en temps r√©el par exemple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"lexique\"><h2 align=\"center\"> Lexique </h2></a>\n",
    "\n",
    "### üìö Terminologie\n",
    "\n",
    "- `DataFrame` ou `df`: structure de donn√©es tabulaires en m√©moire qui permet de stocker et manipuler les colonnes et lignes de donn√©es.\n",
    "\n",
    "### ‚úîÔ∏è Vu dans l'exemple 1\n",
    "\n",
    "- `pd.DataFrame`: cr√©√© un DataFrame √† partir d'un objet Python comme une liste de dictionnaires ou un dictionnaire de listes.\n",
    "- `df.shape`: renvoie la taille du DataFrame.\n",
    "- `df.columns`: renvoie la liste des noms des colonnes.\n",
    "- `df.index`: renvoie les index des lignes.\n",
    "- `df.dtypes`: renvoie le type de donn√©es d'une colonne.\n",
    "- `pd.Series`: cr√©√© une Series (colonne d'un df) √† partir d'une liste de donn√©es. \n",
    "- `pd.concat`: concat√®ne plusieurs DataFrames sur les lignes ou colonnes.\n",
    "- `df.loc`: indexation de plusieurs lignes et colonnes par noms et avec des masques binaires.\n",
    "- `df.iloc`: indexation par num√©ros de lignes et colonnes.\n",
    "- `df.isin`: masque binaire qui renvoie `True` pour les lignes qui contiennent une valeur dans une liste de valeurs possibles.\n",
    "- `df.sort_values`: trie les donn√©es par ordre croissant ou d√©croissant.\n",
    "- `df.to_dict`: convertit un DataFrame en objet Python.\n",
    "- `df.to_numpy`: convertit un DataFrame en matrice NumPy.\n",
    "\n",
    "### ‚úîÔ∏è Vu dans l'exemple 2\n",
    "\n",
    "- `pd.read_csv`: lit un fichier CSV et renvoie un DataFrame.\n",
    "- `df.groupby`: groupe les lignes d'un DataFrame par une ou des colonnes.\n",
    "- `df.agg`: sp√©cifie la m√©thode d'aggregation lors d'un groupby.\n",
    "- `df.rename`: renomme les colonnes d'un DataFrame.\n",
    "- `df.str.contains`: renvoie un masque binaire pour chaque ligne qui contient un ou plusieurs mots.\n",
    "- `df.reset_index`: remet les index √† la valeur par d√©faut.\n",
    "\n",
    "### ‚úîÔ∏è Vu dans l'exemple 3\n",
    "\n",
    "- `df.fillna`: remplace les valeurs nulles par une valeur.\n",
    "- `df.duplicated`: renvoie un masque binaire pour les lignes qui sont dupliqu√©es.\n",
    "- `df.drop_duplicates`: retire les lignes dupliqu√©es.\n",
    "- `df.set_index`: d√©finit la cl√© primaire d'un DataFrame.\n",
    "- `df.merge`: joint deux DataFrames en fonction d'une cl√© commune.\n",
    "- `df.dropna`: retire les lignes ou colonnes qui contiennent des valeurs nulles.\n",
    "- `df.drop`: retire les lignes/colonnes sp√©cifi√©es d'un DataFrame."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "25034407fed5d681614dac11a1c0537e8cb49e3a8883c071303eea01322943d9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
